{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae9a703",
   "metadata": {},
   "source": [
    "# Self Practice15 -Perform Text Preprocessing on your textâ€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad3ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ffd99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AbdulAziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AbdulAziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AbdulAziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AbdulAziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\AbdulAziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\AbdulAziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f88052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c12d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"\"\"\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
    "The ultimate objective of NLP is to read, decipher, understand, and make sense of human languages in a manner that is valuable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcced665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'humans',\n",
       " 'through',\n",
       " 'natural',\n",
       " 'language',\n",
       " '.',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'objective',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'to',\n",
       " 'read',\n",
       " ',',\n",
       " 'decipher',\n",
       " ',',\n",
       " 'understand',\n",
       " ',',\n",
       " 'and',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'in',\n",
       " 'a',\n",
       " 'manner',\n",
       " 'that',\n",
       " 'is',\n",
       " 'valuable',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126bd639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focuses',\n",
       " 'interaction',\n",
       " 'computers',\n",
       " 'humans',\n",
       " 'natural',\n",
       " 'language',\n",
       " '.',\n",
       " 'ultimate',\n",
       " 'objective',\n",
       " 'NLP',\n",
       " 'read',\n",
       " ',',\n",
       " 'decipher',\n",
       " ',',\n",
       " 'understand',\n",
       " ',',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'human',\n",
       " 'languages',\n",
       " 'manner',\n",
       " 'valuable',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e348e6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focus',\n",
       " 'interaction',\n",
       " 'computer',\n",
       " 'human',\n",
       " 'natural',\n",
       " 'language',\n",
       " '.',\n",
       " 'ultimate',\n",
       " 'objective',\n",
       " 'NLP',\n",
       " 'read',\n",
       " ',',\n",
       " 'decipher',\n",
       " ',',\n",
       " 'understand',\n",
       " ',',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'human',\n",
       " 'language',\n",
       " 'manner',\n",
       " 'valuable',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682867e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'field',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'focus',\n",
       " 'interact',\n",
       " 'comput',\n",
       " 'human',\n",
       " 'natur',\n",
       " 'languag',\n",
       " '.',\n",
       " 'ultim',\n",
       " 'object',\n",
       " 'nlp',\n",
       " 'read',\n",
       " ',',\n",
       " 'deciph',\n",
       " ',',\n",
       " 'understand',\n",
       " ',',\n",
       " 'make',\n",
       " 'sens',\n",
       " 'human',\n",
       " 'languag',\n",
       " 'manner',\n",
       " 'valuabl',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19996b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ'),\n",
       " ('Language', 'NNP'),\n",
       " ('Processing', 'NNP'),\n",
       " ('(', '('),\n",
       " ('NLP', 'NNP'),\n",
       " (')', ')'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('focuses', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('interaction', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('computers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('humans', 'NNS'),\n",
       " ('through', 'IN'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('ultimate', 'JJ'),\n",
       " ('objective', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('read', 'VB'),\n",
       " (',', ','),\n",
       " ('decipher', 'RB'),\n",
       " (',', ','),\n",
       " ('understand', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('make', 'VB'),\n",
       " ('sense', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('human', 'JJ'),\n",
       " ('languages', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('manner', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('valuable', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parts of Speech Tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8f2f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural Language Processing (NLP', 'WORK_OF_ART'), ('NLP', 'ORG')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "doc = nlp(text)\n",
    "named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12fad760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 17,\n",
       " 'language': 13,\n",
       " 'processing': 22,\n",
       " 'nlp': 18,\n",
       " 'is': 12,\n",
       " 'field': 5,\n",
       " 'of': 20,\n",
       " 'artificial': 1,\n",
       " 'intelligence': 10,\n",
       " 'that': 25,\n",
       " 'focuses': 6,\n",
       " 'on': 21,\n",
       " 'the': 26,\n",
       " 'interaction': 11,\n",
       " 'between': 2,\n",
       " 'computers': 3,\n",
       " 'and': 0,\n",
       " 'humans': 8,\n",
       " 'through': 27,\n",
       " 'ultimate': 29,\n",
       " 'objective': 19,\n",
       " 'to': 28,\n",
       " 'read': 23,\n",
       " 'decipher': 4,\n",
       " 'understand': 30,\n",
       " 'make': 15,\n",
       " 'sense': 24,\n",
       " 'human': 7,\n",
       " 'languages': 14,\n",
       " 'in': 9,\n",
       " 'manner': 16,\n",
       " 'valuable': 31}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform([text])\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
